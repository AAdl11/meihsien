"""
Journey of Kindness - Story-Driven AI Educational Game Backend
==============================================================

Author: Mei Hsien Hsu
Course: CS4 Introduction to Artificial Intelligence
Institution: Las Positas College, Honors Transfer Program
Instructor: Professor An Lam
Date: November 2, 2025

Mission: Recruit 500+ volunteers for Tzu Chi Foundation's Hunter's Point service
through emotionally engaging, story-driven AI education games.

Story Origin: The Raw Rice Incident (2000)
A hungry child eating uncooked rice at Hunters Point Elementary sparked
25 years of community service. This game transforms that compassion into
interactive volunteer recruitment through 8 AI-powered mission scenarios.

Design Philosophy:
- Code: 100% English (for professors and GitHub community)
- Game Interface: Bilingual EN + Traditional Chinese (for players)
- Every algorithm wrapped in emotional volunteer story
- Target: 60+ year-old Tzu Chi elders + Chinese-speaking youth

Technical Stack:
- Backend: Python 3.12 (Pyodide in browser)
- Frontend: React.js + GitHub Pages
- Media: Music, images, videos from /assets folder
- Progress: localStorage persistence

Academic Context:
Integrates 8 AI algorithms from Russell & Norvig's "AI: A Modern Approach" (4th Ed)
Target Transfer: UC Berkeley / Stanford Computer Science Programs

License: MIT
Repository: https://github.com/AAdl11/meihsien
"""

import math
import random
import heapq
from typing import List, Tuple, Dict, Optional, Set, Any
from dataclasses import dataclass, field
from collections import deque, defaultdict
from enum import Enum
import json


# =============================================================================
# STORY CONFIGURATION - Links to Media Assets
# =============================================================================

class StoryAssets:
    """
    Media assets for emotional storytelling.
    
    Structure:
    /assets/
      /music/
        - raw_rice_theme.mp3 (Main theme)
        - mission_start.mp3 (Level start)
        - mission_complete.mp3 (Level complete)
      /images/
        - hunters_point_map.jpg (Neighborhood map)
        - raw_rice_incident.jpg (Historic photo)
        - volunteer_stories/ (Real volunteer photos)
      /videos/
        - intro_story.mp4 (Raw Rice Incident narration)
        - volunteer_testimonials.mp4
    """
    
    BASE_PATH = "/assets"
    
    MUSIC = {
        'main_theme': f"{BASE_PATH}/music/raw_rice_theme.mp3",
        'mission_start': f"{BASE_PATH}/music/mission_start.mp3",
        'mission_complete': f"{BASE_PATH}/music/mission_complete.mp3",
        'meditation': f"{BASE_PATH}/music/meditation_calm.mp3"
    }
    
    IMAGES = {
        'hunters_point_map': f"{BASE_PATH}/images/hunters_point_map.jpg",
        'raw_rice_incident': f"{BASE_PATH}/images/raw_rice_incident.jpg",
        'volunteer_group': f"{BASE_PATH}/images/volunteer_stories/group.jpg"
    }
    
    VIDEOS = {
        'intro_story': f"{BASE_PATH}/videos/intro_story.mp4",
        'testimonials': f"{BASE_PATH}/videos/volunteer_testimonials.mp4"
    }


# =============================================================================
# STORY NARRATIVES - Emotional Context for Each Level
# =============================================================================

class StoryNarratives:
    """
    Story-driven descriptions for each AI algorithm mission.
    
    Each level wraps the technical algorithm in an emotional volunteer
    scenario that helps recruit new volunteers by showing real impact.
    """
    
    LEVEL_1_STORY = {
        'title': {
            'en': "ğŸš Food Delivery Mission",
            'zh': "ğŸš é£Ÿç‰©é…é€ä»»å‹™"
        },
        'subtitle': {
            'en': "The Raw Rice Incident Legacy",
            'zh': "ç”Ÿç±³äº‹ä»¶çš„å»¶çºŒ"
        },
        'intro': {
            'en': """
2000, Hunters Point Elementary School.
A little girl, so hungry she couldn't wait,
ate raw, uncooked rice at lunchtime.
Her mother worked three jobs but still
couldn't afford groceries.

That moment changed everything.
For 25 years, Tzu Chi volunteers have delivered
hot meals to families in this forgotten corner
of San Francisco.

Today, YOU are the volunteer driver.
Can you find the fastest route to deliver
warm food to 5 families before dinner gets cold?
""",
            'zh': """
2000å¹´ï¼Œçµäººè§’å°å­¸ã€‚
ä¸€å€‹å°å¥³å­©é¤“åˆ°ç­‰ä¸åŠï¼Œ
åˆé¤æ™‚åƒèµ·äº†ç”Ÿç±³ã€‚
å¥¹åª½åª½æ‰“ä¸‰ä»½å·¥
é‚„æ˜¯è²·ä¸èµ·é£Ÿç‰©ã€‚

é‚£ä¸€åˆ»æ”¹è®Šäº†ä¸€åˆ‡ã€‚
25å¹´ä¾†ï¼Œæ…ˆæ¿Ÿå¿—å·¥æŒçºŒé€ç†±é¨°é¨°çš„é£¯èœ
åˆ°é€™å€‹è¢«éºå¿˜çš„èˆŠé‡‘å±±è§’è½ã€‚

ä»Šå¤©ï¼Œä½ æ˜¯å¿—å·¥å¸æ©Ÿã€‚
ä½ èƒ½æ‰¾åˆ°æœ€å¿«çš„è·¯ç·šï¼Œåœ¨æ™šé¤è®Šå†·å‰
æŠŠæº«æš–çš„é£Ÿç‰©é€åˆ°5å€‹å®¶åº­å—ï¼Ÿ
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: A* pathfinding finds optimal delivery routes",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šA*å°‹è·¯æ‰¾å‡ºæœ€ä½³é…é€è·¯ç·š"
        }
    }
    
    LEVEL_2_STORY = {
        'title': {
            'en': "ğŸ’” Difficult Choices",
            'zh': "ğŸ’” è‰±é›£çš„æŠ‰æ“‡"
        },
        'subtitle': {
            'en': "Strategic Resource Allocation",
            'zh': "ç­–ç•¥è³‡æºåˆ†é…"
        },
        'intro': {
            'en': """
After the Raw Rice Incident, we created
an emergency relief fund: $10,000 for families
in crisis.

But the needs are overwhelming:
- Family A: $3,000 medical bills (Mom has diabetes)
- Family B: $8,000 rent to avoid eviction
- Family C: $1,500 school supplies (3 kids)
- Family D: $50,000 housing repair (roof collapse)

You can't help everyone who needs $50K.
Sometimes compassion means making hard choices.

Which families should we prioritize?
How do we maximize impact with limited resources?
""",
            'zh': """
ç”Ÿç±³äº‹ä»¶å¾Œï¼Œæˆ‘å€‘å‰µå»ºäº†
ç·Šæ€¥æ•‘åŠ©åŸºé‡‘ï¼šä¸€è¬ç¾å…ƒå¹«åŠ©å±æ©Ÿå®¶åº­ã€‚

ä½†éœ€æ±‚å¤ªé¾å¤§äº†ï¼š
- Aå®¶åº­ï¼š$3,000é†«ç™‚è²»ï¼ˆåª½åª½æœ‰ç³–å°¿ç—…ï¼‰
- Bå®¶åº­ï¼š$8,000æˆ¿ç§Ÿï¼ˆé¿å…è¢«è¶•å‡ºå»ï¼‰
- Cå®¶åº­ï¼š$1,500å­¸ç”¨å“ï¼ˆ3å€‹å­©å­ï¼‰
- Då®¶åº­ï¼š$50,000æˆ¿å±‹ä¿®ç¹•ï¼ˆå±‹é ‚å¡Œäº†ï¼‰

ä½ ç„¡æ³•å¹«åŠ©æ‰€æœ‰éœ€è¦$50Kçš„äººã€‚
æœ‰æ™‚å€™æ…ˆæ‚²æ„å‘³è‘—åšå‡ºè‰±é›£çš„é¸æ“‡ã€‚

æˆ‘å€‘æ‡‰è©²å„ªå…ˆå¹«åŠ©å“ªäº›å®¶åº­ï¼Ÿ
å¦‚ä½•ç”¨æœ‰é™è³‡æºæœ€å¤§åŒ–å½±éŸ¿åŠ›ï¼Ÿ
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: Alpha-Beta pruning eliminates 'obviously impossible' options fast",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šAlpha-Betaå‰ªæå¿«é€Ÿæ’é™¤ã€Œæ˜é¡¯ä¸å¯èƒ½ã€çš„é¸é …"
        }
    }
    
    LEVEL_3_STORY = {
        'title': {
            'en': "ğŸ¤ Will They Come Back?",
            'zh': "ğŸ¤ ä»–å€‘æœƒå›ä¾†å—ï¼Ÿ"
        },
        'subtitle': {
            'en': "Predicting Volunteer Commitment",
            'zh': "é æ¸¬å¿—å·¥æ‰¿è«¾åº¦"
        },
        'intro': {
            'en': """
Maria came once to help distribute food.
She was moved to tears seeing the families.
But will she come back next month?

Our volunteers are aging (average age: 65).
We NEED young people like Maria to continue
this 25-year legacy.

Based on what we know:
- Is she experiencing hardship herself?
- Does she have time availability?
- Does her personality fit volunteer work?

AI helps us predict: Should we reach out
actively, or give her space?
""",
            'zh': """
Mariaä¾†äº†ä¸€æ¬¡å¹«å¿™ç™¼æ”¾é£Ÿç‰©ã€‚
å¥¹çœ‹åˆ°é€™äº›å®¶åº­æ„Ÿå‹•è½æ·šã€‚
ä½†å¥¹ä¸‹å€‹æœˆæœƒå›ä¾†å—ï¼Ÿ

æˆ‘å€‘çš„å¿—å·¥åœ¨è€åŒ–ï¼ˆå¹³å‡å¹´é½¡65æ­²ï¼‰ã€‚
æˆ‘å€‘éœ€è¦åƒMariaé€™æ¨£çš„å¹´è¼•äºº
å»¶çºŒé€™25å¹´çš„ä½¿å‘½ã€‚

æ ¹æ“šæˆ‘å€‘æ‰€çŸ¥ï¼š
- å¥¹è‡ªå·±æœ‰ç¶“æ­·å›°é›£å—ï¼Ÿ
- å¥¹æœ‰æ™‚é–“å—ï¼Ÿ
- å¥¹çš„å€‹æ€§é©åˆå¿—å·¥å·¥ä½œå—ï¼Ÿ

AIå¹«æˆ‘å€‘é æ¸¬ï¼šæˆ‘å€‘æ‡‰è©²ä¸»å‹•è¯ç¹«ï¼Œ
é‚„æ˜¯çµ¦å¥¹ç©ºé–“ï¼Ÿ
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: Bayesian Networks calculate commitment probability",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šè²è‘‰æ–¯ç¶²çµ¡è¨ˆç®—æ‰¿è«¾æ¦‚ç‡"
        }
    }
    
    LEVEL_4_STORY = {
        'title': {
            'en': "ğŸ§˜ Building Virtue, One Layer at a Time",
            'zh': "ğŸ§˜ é€å±¤å»ºç«‹ç¾å¾·"
        },
        'subtitle': {
            'en': "The Tower of Compassion",
            'zh': "æ…ˆæ‚²ä¹‹å¡”"
        },
        'intro': {
            'en': """
Master Cheng Yen teaches:
"Gratitude is the foundation.
Respect stands upon gratitude.
Love grows from respect."

Like the Tower of Hanoi puzzle,
you can't skip steps in building compassion.
You must build virtue one layer at a time,
one action at a time.

Move the disks from "Self-Interest"
to "Serving Others."
But follow the rules: Never place
a larger burden on a smaller foundation.
""",
            'zh': """
è­‰åš´ä¸Šäººæ•™å°ï¼š
ã€Œæ„Ÿæ©æ˜¯åŸºç¤ã€‚
å°Šé‡ç«‹æ–¼æ„Ÿæ©ä¹‹ä¸Šã€‚
æ„›å¾å°Šé‡ä¸­ç”Ÿé•·ã€‚ã€

å°±åƒæ²³å…§å¡”çš„è¬é¡Œï¼Œ
ä½ ä¸èƒ½è·³éå»ºç«‹æ…ˆæ‚²çš„æ­¥é©Ÿã€‚
ä½ å¿…é ˆé€å±¤å»ºç«‹ç¾å¾·ï¼Œ
ä¸€æ¬¡ä¸€å€‹è¡Œå‹•ã€‚

æŠŠåœ“ç›¤å¾ã€Œè‡ªåˆ©ã€
ç§»åˆ°ã€Œåˆ©ä»–ã€ã€‚
ä½†è¦éµå®ˆè¦å‰‡ï¼šæ°¸é ä¸è¦æŠŠ
æ›´å¤§çš„è² æ“”æ”¾åœ¨æ›´å°çš„åŸºç¤ä¸Šã€‚
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: Recursive thinking shows optimal 2^n - 1 moves",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šéæ­¸æ€ç¶­å±•ç¤ºæœ€å„ª2^n - 1æ­¥"
        }
    }
    
    LEVEL_5_STORY = {
        'title': {
            'en': "ğŸ“… Volunteer Shift Scheduler",
            'zh': "ğŸ“… å¿—å·¥æ’ç­èª¿åº¦"
        },
        'subtitle': {
            'en': "8 Volunteers, 8 Shifts, Zero Conflicts",
            'zh': "8ä½å¿—å·¥ï¼Œ8å€‹ç­æ¬¡ï¼Œé›¶è¡çª"
        },
        'intro': {
            'en': """
Saturday food distribution needs 8 volunteers:
- Morning setup (6am-9am)
- Registration desk (9am-12pm)
- Food sorting (9am-12pm)
- Distribution (12pm-3pm)
- Cleanup (3pm-6pm)
... and 3 more shifts

But everyone has conflicts:
Mrs. Chen can't work mornings (arthritis pain).
David has basketball practice at 3pm.
Rosa works until noon.

Can you arrange 8 people across 8 time slots
so NOBODY has conflicts?
Like the N-Queens puzzle: no attacks allowed!
""",
            'zh': """
é€±å…­é£Ÿç‰©ç™¼æ”¾éœ€è¦8ä½å¿—å·¥ï¼š
- æ—©æ™¨æº–å‚™ï¼ˆ6am-9amï¼‰
- è¨»å†Šæ¡Œï¼ˆ9am-12pmï¼‰
- é£Ÿç‰©åˆ†é¡ï¼ˆ9am-12pmï¼‰
- ç™¼æ”¾ï¼ˆ12pm-3pmï¼‰
- æ¸…æ½”ï¼ˆ3pm-6pmï¼‰
... é‚„æœ‰3å€‹ç­æ¬¡

ä½†æ¯å€‹äººéƒ½æœ‰è¡çªï¼š
é™³å¤ªå¤ªæ—©ä¸Šä¸èƒ½å·¥ä½œï¼ˆé—œç¯€ç‚ç—›ï¼‰ã€‚
Davidä¸‹åˆ3é»æœ‰ç±ƒçƒç·´ç¿’ã€‚
Rosaè¦å·¥ä½œåˆ°ä¸­åˆã€‚

ä½ èƒ½æŠŠ8å€‹äººå®‰æ’åœ¨8å€‹æ™‚æ®µ
è®“æ‰€æœ‰äººéƒ½æ²’æœ‰è¡çªå—ï¼Ÿ
å°±åƒNçš‡åè¬é¡Œï¼šä¸å…è¨±æ”»æ“Šï¼
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: Backtracking with constraint satisfaction",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šå›æº¯æ³•åŠ ç´„æŸæ»¿è¶³"
        }
    }
    
    LEVEL_6_STORY = {
        'title': {
            'en': "ğŸ§˜ Finding Inner Peace",
            'zh': "ğŸ§˜ å°‹æ‰¾å…§å¿ƒå¹³å’Œ"
        },
        'subtitle': {
            'en': "Meditation Optimization",
            'zh': "ç¦ªä¿®å„ªåŒ–"
        },
        'intro': {
            'en': """
After 8 hours of food distribution,
volunteers gather for evening meditation.

"Find your inner peace," the guide says.
But what IS inner peace?
- Focus without distraction?
- Calmness without worry?
- Compassion without judgment?

Master Cheng Yen teaches:
"When the mind is calm, wisdom appears."

Try different meditation states.
Climb the hill toward optimal peace.
But beware: You might get stuck in
comfortable but not perfect states (local maxima).

That's when you need to "restart" - try again!
""",
            'zh': """
ç™¼æ”¾é£Ÿç‰©8å°æ™‚å¾Œï¼Œ
å¿—å·¥å€‘èšåœ¨ä¸€èµ·æ™šé–“ç¦ªä¿®ã€‚

ã€Œæ‰¾åˆ°ä½ çš„å…§å¿ƒå¹³å’Œï¼Œã€å°å¸«èªªã€‚
ä½†ä»€éº¼æ˜¯å…§å¿ƒå¹³å’Œï¼Ÿ
- å°ˆæ³¨è€Œä¸åˆ†å¿ƒï¼Ÿ
- å¹³éœè€Œä¸æ“”æ†‚ï¼Ÿ
- æ…ˆæ‚²è€Œä¸æ‰¹åˆ¤ï¼Ÿ

è­‰åš´ä¸Šäººæ•™å°ï¼š
ã€Œå¿ƒéœï¼Œæ™ºæ…§è‡ªç„¶ç”Ÿã€‚ã€

å˜—è©¦ä¸åŒçš„ç¦ªä¿®ç‹€æ…‹ã€‚
çˆ¬å‘æœ€å„ªçš„å¹³å’Œä¹‹å·”ã€‚
ä½†è¦å°å¿ƒï¼šä½ å¯èƒ½å›°åœ¨
èˆ’é©ä½†ä¸å®Œç¾çš„ç‹€æ…‹ï¼ˆå±€éƒ¨æœ€å¤§å€¼ï¼‰ã€‚

é€™æ™‚ä½ éœ€è¦ã€Œé‡æ–°é–‹å§‹ã€â€”â€”å†è©¦ä¸€æ¬¡ï¼
"""
        },
        'algorithm_hint': {
            'en': "ğŸ’¡ AI Helper: Hill climbing with random restarts escapes local maxima",
            'zh': "ğŸ’¡ AIå¹«æ‰‹ï¼šçˆ¬å±±æ³•åŠ éš¨æ©Ÿé‡å•Ÿé€ƒé›¢å±€éƒ¨æœ€å¤§å€¼"
        }
    }


# =============================================================================
# CORE GAME ENGINE WITH STORY INTEGRATION
# =============================================================================

class GameEngine:
    """
    Master controller for story-driven AI missions.
    
    Manages:
    - 8 story-wrapped AI algorithms
    - Bilingual story delivery
    - Human vs AI comparison
    - Elo rating progression
    - Media asset loading
    """
    
    def __init__(self):
        """Initialize game engine with story and algorithm instances."""
        self.algorithms = {
            'astar': AStarSearch(),
            'alphabeta': AlphaBetaPruning(),
            'bayesian': BayesianNetwork(),
            'hanoi': TowerOfHanoi(),
            'nqueens': NQueensSolver(),
            'hillclimb': HillClimbing(),
            'fol': FOLPlanner(),
            'blocks': BlocksWorld()
        }
        
        self.stories = StoryNarratives()
        self.assets = StoryAssets()
        self.elo_system = EloRating(initial=1000, k=32)
        self.current_level = 1
        self.completed_levels = set()
        
    def get_level_story(self, level_id: int, language: str = 'both') -> Dict[str, Any]:
        """
        Get story introduction for a level.
        
        Args:
            level_id: Mission number (1-8)
            language: 'en', 'zh', or 'both' (default)
            
        Returns:
            {
                'title': bilingual title,
                'subtitle': bilingual subtitle,
                'intro': story text,
                'algorithm_hint': what AI does,
                'media': {music, images, videos}
            }
        """
        story_map = {
            1: self.stories.LEVEL_1_STORY,
            2: self.stories.LEVEL_2_STORY,
            3: self.stories.LEVEL_3_STORY,
            4: self.stories.LEVEL_4_STORY,
            5: self.stories.LEVEL_5_STORY,
            6: self.stories.LEVEL_6_STORY
        }
        
        story = story_map.get(level_id, {})
        
        # Format based on language preference
        if language == 'en':
            formatted = {k: v.get('en', '') for k, v in story.items() if isinstance(v, dict)}
        elif language == 'zh':
            formatted = {k: v.get('zh', '') for k, v in story.items() if isinstance(v, dict)}
        else:  # both
            formatted = story
        
        # Add media assets
        formatted['media'] = {
            'music': self.assets.MUSIC['mission_start'],
            'background': self.assets.IMAGES.get(f'level_{level_id}_bg', '')
        }
        
        return formatted
    
    def run_level(self, level_id: int, user_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute story-driven mission with AI comparison.
        
        Flow:
        1. Show story introduction (bilingual)
        2. Player attempts mission
        3. AI demonstrates optimal solution
        4. Compare results with emotional feedback
        5. Update Elo and unlock rewards
        
        Args:
            level_id: Mission number (1-8)
            user_input: Player's solution attempt
            
        Returns:
            {
                'story': mission context,
                'user_solution': player attempt,
                'ai_solution': optimal solution,
                'comparison': human vs AI,
                'emotional_feedback': bilingual encouragement,
                'elo_change': rating adjustment,
                'rewards': unlocked content
            }
        """
        algorithm_map = {
            1: 'astar',
            2: 'alphabeta',
            3: 'bayesian',
            4: 'hanoi',
            5: 'nqueens',
            6: 'hillclimb',
            7: 'fol',
            8: 'blocks'
        }
        
        if level_id not in algorithm_map:
            raise ValueError(f"Invalid level ID: {level_id}")
        
        # Get story context
        story = self.get_level_story(level_id)
        
        # Execute algorithm
        algorithm = self.algorithms[algorithm_map[level_id]]
        ai_result = algorithm.solve(user_input)
        
        # Calculate user performance
        user_score = self._evaluate_user_performance(
            level_id, user_input, ai_result
        )
        
        # Update Elo
        elo_change = self.elo_system.calculate(user_score, ai_result.get('score', 100))
        
        # Track progress
        if user_score >= 70:
            self.completed_levels.add(level_id)
        
        # Generate emotional feedback (bilingual)
        emotional_feedback = self._generate_emotional_feedback(
            level_id, user_score, elo_change
        )
        
        return {
            'story': story,
            'user_solution': user_input,
            'ai_solution': ai_result['solution'],
            'ai_explanation': ai_result['explanation'],
            'comparison': {
                'user_score': user_score,
                'ai_score': ai_result.get('score', 100),
                'difference': abs(ai_result.get('score', 100) - user_score),
                'improvement_tips': self._get_improvement_tips(level_id, user_score, ai_result)
            },
            'emotional_feedback': emotional_feedback,
            'elo_change': elo_change,
            'current_elo': self.elo_system.rating,
            'rewards': {
                'next_level_unlocked': len(self.completed_levels) >= level_id,
                'tzuchi_qr_unlocked': self.elo_system.rating >= 1300,
                'rank': self.elo_system.get_rank()
            }
        }
    
    def _generate_emotional_feedback(
        self,
        level_id: int,
        user_score: float,
        elo_change: int
    ) -> Dict[str, str]:
        """
        Generate encouraging bilingual feedback based on performance.
        
        Design: Always encouraging, never discouraging.
        Even "failure" is framed as learning opportunity.
        """
        if user_score >= 90:
            return {
                'en': f"""
ğŸŒŸ OUTSTANDING! | éå¸¸å‡ºè‰²ï¼
You're thinking like a veteran volunteer!
Your solution scored {user_score:.0f}/100.

The families you helped today will remember
your efficiency and care. Thank you! ğŸ™

Elo Rating: +{elo_change} â†’ {self.elo_system.rating}
""",
                'zh': f"""
ğŸŒŸ éå¸¸å‡ºè‰²ï¼| OUTSTANDING!
ä½ çš„æ€è€ƒæ–¹å¼åƒè³‡æ·±å¿—å·¥ï¼
ä½ çš„è§£æ±ºæ–¹æ¡ˆå¾—åˆ† {user_score:.0f}/100ã€‚

ä½ ä»Šå¤©å¹«åŠ©çš„å®¶åº­æœƒè¨˜å¾—
ä½ çš„æ•ˆç‡å’Œé—œæ‡·ã€‚æ„Ÿæ©ï¼ğŸ™

Eloè©•åˆ†ï¼š+{elo_change} â†’ {self.elo_system.rating}
"""
            }
        elif user_score >= 70:
            return {
                'en': f"""
ğŸ’š WELL DONE! | åšå¾—å¥½ï¼
You completed the mission successfully!
Score: {user_score:.0f}/100

There's always room to grow, but today
you made a real difference. Keep going!

Elo Rating: +{elo_change} â†’ {self.elo_system.rating}
""",
                'zh': f"""
ğŸ’š åšå¾—å¥½ï¼| WELL DONE!
ä½ æˆåŠŸå®Œæˆäº†ä»»å‹™ï¼
å¾—åˆ†ï¼š{user_score:.0f}/100

ç¸½æœ‰æˆé•·ç©ºé–“ï¼Œä½†ä»Šå¤©
ä½ ç¢ºå¯¦æœ‰æ‰€ä½œç‚ºã€‚ç¹¼çºŒåŠ æ²¹ï¼

Eloè©•åˆ†ï¼š+{elo_change} â†’ {self.elo_system.rating}
"""
            }
        else:
            return {
                'en': f"""
ğŸ’™ LEARNING IN PROGRESS | å­¸ç¿’ä¸­
Every expert volunteer was once a beginner.
Score: {user_score:.0f}/100

Master Cheng Yen says: "Failure is the mother
of success." Try again with the AI's guidance!

Elo Rating: {elo_change:+d} â†’ {self.elo_system.rating}
""",
                'zh': f"""
ğŸ’™ å­¸ç¿’ä¸­ | LEARNING IN PROGRESS
æ¯ä½è³‡æ·±å¿—å·¥éƒ½æ›¾æ˜¯æ–°æ‰‹ã€‚
å¾—åˆ†ï¼š{user_score:.0f}/100

è­‰åš´ä¸Šäººèªªï¼šã€Œå¤±æ•—ç‚ºæˆåŠŸä¹‹æ¯ã€‚ã€
è·Ÿè‘—AIçš„å¼•å°å†è©¦ä¸€æ¬¡ï¼

Eloè©•åˆ†ï¼š{elo_change:+d} â†’ {self.elo_system.rating}
"""
            }
    
    def _get_improvement_tips(
        self,
        level_id: int,
        user_score: float,
        ai_result: Dict[str, Any]
    ) -> List[Dict[str, str]]:
        """
        Generate bilingual improvement tips.
        
        Returns list of {en: ..., zh: ...} tip dictionaries.
        """
        tips = []
        
        if level_id == 1:  # A* Search
            if user_score < 70:
                tips.append({
                    'en': "ğŸ’¡ Try using Manhattan distance to estimate remaining distance",
                    'zh': "ğŸ’¡ è©¦è©¦ä½¿ç”¨æ›¼å“ˆé “è·é›¢ä¾†ä¼°è¨ˆå‰©é¤˜è·é›¢"
                })
                tips.append({
                    'en': "ğŸ’¡ Always explore the path with lowest f(n) = g(n) + h(n) first",
                    'zh': "ğŸ’¡ ç¸½æ˜¯å…ˆæ¢ç´¢f(n) = g(n) + h(n)æœ€ä½çš„è·¯å¾‘"
                })
        
        elif level_id == 2:  # Alpha-Beta
            if user_score < 70:
                tips.append({
                    'en': "ğŸ’¡ Think: Which families can we definitely NOT help with $10K?",
                    'zh': "ğŸ’¡ æƒ³æƒ³ï¼šå“ªäº›å®¶åº­æˆ‘å€‘ç”¨$10Kçµ•å°å¹«ä¸äº†ï¼Ÿ"
                })
                tips.append({
                    'en': "ğŸ’¡ Those 'obviously impossible' options are what Alpha-Beta prunes!",
                    'zh': "ğŸ’¡ é‚£äº›ã€Œæ˜é¡¯ä¸å¯èƒ½ã€çš„é¸é …å°±æ˜¯Alpha-Betaæœƒå‰ªæçš„ï¼"
                })
        
        elif level_id == 3:  # Bayesian
            if user_score < 70:
                tips.append({
                    'en': "ğŸ’¡ People who received help are more likely to give back",
                    'zh': "ğŸ’¡ å—éå¹«åŠ©çš„äººæ›´å¯èƒ½å›é¥‹"
                })
                tips.append({
                    'en': "ğŸ’¡ Use Bayes' Theorem: P(A|B) = P(B|A) Ã— P(A) / P(B)",
                    'zh': "ğŸ’¡ ä½¿ç”¨è²è‘‰æ–¯å®šç†ï¼šP(A|B) = P(B|A) Ã— P(A) / P(B)"
                })
        
        # Universal encouragement
        if user_score >= 90:
            tips.insert(0, {
                'en': "ğŸŒŸ Excellent! You're thinking like the AI!",
                'zh': "ğŸŒŸ å¤ªæ£’äº†ï¼ä½ çš„æ€è€ƒæ–¹å¼åƒAIä¸€æ¨£ï¼"
            })
        elif user_score >= 70:
            tips.insert(0, {
                'en': "ğŸ‘ Good job! Small improvements possible",
                'zh': "ğŸ‘ åšå¾—å¥½ï¼é‚„æœ‰å°çš„æ”¹é€²ç©ºé–“"
            })
        else:
            tips.insert(0, {
                'en': "ğŸ“š Study the AI's approach - it shows the optimal strategy",
                'zh': "ğŸ“š ç ”ç©¶AIçš„æ–¹æ³• â€” å®ƒå±•ç¤ºäº†æœ€å„ªç­–ç•¥"
            })
        
        return tips
    
    def _evaluate_user_performance(
        self,
        level_id: int,
        user_input: Dict[str, Any],
        ai_result: Dict[str, Any]
    ) -> float:
        """Evaluate user performance (0-100 scale)."""
        if level_id == 1:  # A* Search
            user_path = user_input.get('path', [])
            optimal_path = ai_result['solution'].get('path', [])
            if len(user_path) == 0:
                return 0
            return min(100, (len(optimal_path) / len(user_path)) * 100)
        
        elif level_id == 2:  # Alpha-Beta
            user_value = user_input.get('value', 0)
            optimal_value = ai_result['solution'].get('value', 0)
            return 100 if user_value == optimal_value else 50
        
        elif level_id == 3:  # Bayesian
            user_prob = user_input.get('probability', 0)
            optimal_prob = ai_result['solution'].get('probability', 0)
            diff = abs(user_prob - optimal_prob)
            return max(0, 100 - (diff * 100))
        
        elif level_id in [4, 5, 6]:  # Hanoi, N-Queens, Hill Climbing
            user_moves = user_input.get('moves', float('inf'))
            optimal_moves = ai_result['solution'].get('moves', 1)
            if user_moves == optimal_moves:
                return 100
            elif user_moves <= optimal_moves * 1.5:
                return 75
            else:
                return 50
        
        else:
            return 50


# =============================================================================
# LEVEL 1: A* SEARCH - FOOD DELIVERY MISSION
# =============================================================================

@dataclass
class Node:
    """Search node for A* pathfinding algorithm."""
    position: Tuple[int, int]
    g_cost: float = 0
    h_cost: float = 0
    f_cost: float = 0
    parent: Optional['Node'] = None
    
    def __lt__(self, other):
        return self.f_cost < other.f_cost
    
    def __eq__(self, other):
        return self.position == other.position
    
    def __hash__(self):
        return hash(self.position)


class Grid:
    """2D grid for Hunters Point neighborhood map."""
    
    def __init__(self, width: int, height: int):
        self.width = width
        self.height = height
        self.grid = [[0 for _ in range(width)] for _ in range(height)]
    
    def is_walkable(self, pos: Tuple[int, int]) -> bool:
        x, y = pos
        return (0 <= x < self.width and
                0 <= y < self.height and
                self.grid[y][x] != 1)
    
    def get_neighbors(self, pos: Tuple[int, int]) -> List[Tuple[int, int]]:
        x, y = pos
        neighbors = [(x+1, y), (x-1, y), (x, y+1), (x, y-1)]
        return [n for n in neighbors if self.is_walkable(n)]
    
    def set_obstacle(self, x: int, y: int):
        if 0 <= x < self.width and 0 <= y < self.height:
            self.grid[y][x] = 1
    
    def set_goal(self, x: int, y: int, goal_id: int):
        if 0 <= x < self.width and 0 <= y < self.height:
            self.grid[y][x] = goal_id


class AStarSearch:
    """
    A* Pathfinding Algorithm (Russell & Norvig Chapter 3.5)
    
    Story: Find optimal route to deliver hot meals to families
    Algorithm: A* with Manhattan distance heuristic
    Complexity: O(b^d) where b=branching factor, d=depth
    """
    
    def __init__(self):
        self.stats = {
            'nodes_expanded': 0,
            'nodes_generated': 0,
            'path_cost': 0
        }
    
    def manhattan_distance(self, pos1: Tuple[int, int], pos2: Tuple[int, int]) -> float:
        """Manhattan distance heuristic (admissible for 4-directional grid)."""
        return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])
    
    def reconstruct_path(self, node: Node) -> List[Tuple[int, int]]:
        """Backtrack from goal to start using parent pointers."""
        path = []
        current = node
        while current:
            path.append(current.position)
            current = current.parent
        return path[::-1]
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute A* search for food delivery route.
        
        Args:
            input_data: {
                'grid_size': (width, height),
                'start': (x, y),
                'goals': [(x, y), ...],
                'obstacles': [(x, y), ...]
            }
        
        Returns:
            {
                'solution': {path, cost},
                'explanation': bilingual story,
                'score': 100
            }
        """
        # Initialize grid
        width, height = input_data.get('grid_size', (10, 10))
        grid = Grid(width, height)
        
        for obs in input_data.get('obstacles', []):
            grid.set_obstacle(*obs)
        
        start = input_data.get('start', (0, 0))
        goals = input_data.get('goals', [(9, 9)])
        
        # A* algorithm
        open_set = []
        closed_set = set()
        
        start_node = Node(
            position=start,
            g_cost=0,
            h_cost=min(self.manhattan_distance(start, g) for g in goals),
            f_cost=0
        )
        start_node.f_cost = start_node.g_cost + start_node.h_cost
        
        heapq.heappush(open_set, start_node)
        self.stats['nodes_generated'] = 1
        
        while open_set:
            current = heapq.heappop(open_set)
            self.stats['nodes_expanded'] += 1
            
            if current.position in goals:
                path = self.reconstruct_path(current)
                return {
                    'solution': {
                        'path': path,
                        'cost': current.g_cost,
                        'families_reached': len([p for p in path if p in goals])
                    },
                    'explanation': self._generate_story_explanation(path, current.g_cost),
                    'score': 100
                }
            
            closed_set.add(current.position)
            
            for neighbor_pos in grid.get_neighbors(current.position):
                if neighbor_pos in closed_set:
                    continue
                
                g_cost = current.g_cost + 1
                h_cost = min(self.manhattan_distance(neighbor_pos, g) for g in goals)
                f_cost = g_cost + h_cost
                
                neighbor = Node(
                    position=neighbor_pos,
                    g_cost=g_cost,
                    h_cost=h_cost,
                    f_cost=f_cost,
                    parent=current
                )
                
                if any(n.position == neighbor_pos and n.f_cost <= f_cost for n in open_set):
                    continue
                
                heapq.heappush(open_set, neighbor)
                self.stats['nodes_generated'] += 1
        
        return {
            'solution': {'path': [], 'cost': float('inf')},
            'explanation': "No path found | ç„¡æ³•æ‰¾åˆ°è·¯å¾‘",
            'score': 0
        }
    
    def _generate_story_explanation(self, path: List[Tuple[int, int]], cost: float) -> str:
        """Generate bilingual story-driven explanation."""
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸš FOOD DELIVERY MISSION COMPLETE | é£Ÿç‰©é…é€ä»»å‹™å®Œæˆ        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ YOUR ROUTE | ä½ çš„è·¯ç·š:
{' â†’ '.join(f'({x},{y})' for x, y in path[:10])}
{'...' if len(path) > 10 else ''}

ğŸ“Š MISSION STATS | ä»»å‹™çµ±è¨ˆ:
Total Distance | ç¸½è·é›¢: {cost} blocks | å€‹è¡—å€
Delivery Stops | é…é€ç«™é»: {len(path)} locations | å€‹åœ°é»
Algorithm Efficiency | ç®—æ³•æ•ˆç‡: {self.stats['nodes_expanded']} decisions | å€‹æ±ºç­–

ğŸ¯ IMPACT | å½±éŸ¿:
âœ“ All families received hot meals before 6pm
  æ‰€æœ‰å®¶åº­åœ¨6é»å‰æ”¶åˆ°ç†±é¨°é¨°çš„é£¯èœ
âœ“ Optimal route saved 15 minutes of drive time
  æœ€å„ªè·¯ç·šç¯€çœ15åˆ†é˜è»Šç¨‹
âœ“ Fresh food = healthier families = stronger community
  æ–°é®®é£Ÿç‰© = æ›´å¥åº·çš„å®¶åº­ = æ›´å¼·å¤§çš„ç¤¾å€

ğŸ’­ REFLECTION | åæ€:
"In 2000, that little girl ate raw rice because
food arrived too late. Today, YOUR efficiency
ensures no child goes hungry."

ã€Œ2000å¹´ï¼Œé‚£å€‹å°å¥³å­©åƒç”Ÿç±³æ˜¯å› ç‚º
é£Ÿç‰©é€å¤ªæ™šã€‚ä»Šå¤©ï¼Œä½ çš„æ•ˆç‡
ç¢ºä¿æ²’æœ‰å­©å­æŒ¨é¤“ã€‚ã€

â€” Master Cheng Yen | è­‰åš´ä¸Šäºº

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
A* Search uses h(n) = Manhattan Distance to
estimate remaining path. This "æ™ºæ…§çŒœæ¸¬" makes
it MUCH faster than brute-force search!

A*æœå°‹ä½¿ç”¨h(n) = æ›¼å“ˆé “è·é›¢ä¾†
ä¼°è¨ˆå‰©é¤˜è·¯å¾‘ã€‚é€™å€‹ã€Œæ™ºæ…§çŒœæ¸¬ã€è®“å®ƒ
æ¯”æš´åŠ›æœå°‹å¿«å¾—å¤šï¼

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 2: STRATEGIC RESOURCE ALLOCATION - ALPHA-BETA PRUNING
# =============================================================================

@dataclass
class GameTreeNode:
    """Decision tree node for resource allocation."""
    value: Optional[int] = None
    children: List['GameTreeNode'] = field(default_factory=list)
    is_max: bool = True
    alpha: float = -math.inf
    beta: float = math.inf
    pruned: bool = False
    
    def is_terminal(self) -> bool:
        return len(self.children) == 0


class AlphaBetaPruning:
    """
    Alpha-Beta Pruning for Strategic Resource Allocation
    (Russell & Norvig Chapter 5.3)
    
    Story: $10K emergency fund, multiple families in crisis, hard choices
    Algorithm: Minimax with Î±-Î² pruning
    Teaching Modes: Tutorial (2 mistakes), Learning (1 mistake), Expert (perfect)
    """
    
    def __init__(self, difficulty='learning'):
        self.difficulty = difficulty
        self.stats = {
            'nodes_evaluated': 0,
            'nodes_pruned': 0,
            'max_depth': 0,
            'ai_mistakes_made': 0,
            'teaching_hints': []
        }
    
    def minimax(
        self,
        node: GameTreeNode,
        depth: int,
        alpha: float,
        beta: float,
        maximizing: bool,
        teaching_mode: bool = False
    ) -> int:
        """Minimax with alpha-beta pruning and optional teaching mistakes."""
        self.stats['nodes_evaluated'] += 1
        self.stats['max_depth'] = max(self.stats['max_depth'], depth)
        
        if depth == 0 or node.is_terminal():
            return node.value if node.value is not None else 0
        
        # Teaching mode: Occasionally make suboptimal choices
        if teaching_mode and self._should_make_teaching_mistake(depth):
            values = [
                self.minimax(child, depth - 1, alpha, beta, not maximizing, teaching_mode)
                for child in node.children
            ]
            
            if maximizing and len(values) > 1:
                sorted_values = sorted(enumerate(values), key=lambda x: x[1], reverse=True)
                if len(sorted_values) > 1:
                    self.stats['ai_mistakes_made'] += 1
                    self.stats['teaching_hints'].append({
                        'en': f"ğŸ“ AI Teaching: I chose {sorted_values[1][1]} instead of optimal {sorted_values[0][1]} to give you a chance!",
                        'zh': f"ğŸ“ AIæ•™å­¸ï¼šæˆ‘é¸æ“‡äº†{sorted_values[1][1]}è€Œéæœ€å„ª{sorted_values[0][1]}ä¾†çµ¦ä½ æ©Ÿæœƒï¼"
                    })
                    return sorted_values[1][1]
        
        if maximizing:
            value = -math.inf
            for child in node.children:
                value = max(value, self.minimax(child, depth - 1, alpha, beta, False, teaching_mode))
                alpha = max(alpha, value)
                if beta <= alpha:
                    self.stats['nodes_pruned'] += len(node.children) - (node.children.index(child) + 1)
                    child.pruned = True
                    break
            return value
        else:
            value = math.inf
            for child in node.children:
                value = min(value, self.minimax(child, depth - 1, alpha, beta, True, teaching_mode))
                beta = min(beta, value)
                if beta <= alpha:
                    self.stats['nodes_pruned'] += len(node.children) - (node.children.index(child) + 1)
                    child.pruned = True
                    break
            return value
    
    def _should_make_teaching_mistake(self, depth: int) -> bool:
        """Decide if AI should make intentional mistake for teaching."""
        if self.difficulty == 'tutorial':
            return depth in [2, 1] and self.stats['ai_mistakes_made'] < 2
        elif self.difficulty == 'learning':
            return depth == 1 and self.stats['ai_mistakes_made'] < 1
        else:
            return False
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute strategic resource allocation decision.
        
        Args:
            input_data: {
                'tree_structure': 'simple' | 'complex',
                'difficulty': 'tutorial' | 'learning' | 'expert'
            }
        
        Returns:
            {
                'solution': {value, families_helped},
                'explanation': bilingual story,
                'teaching_hints': list of hints,
                'score': 100
            }
        """
        tree_type = input_data.get('tree_structure', 'simple')
        difficulty = input_data.get('difficulty', self.difficulty)
        
        self.difficulty = difficulty
        self.stats = {
            'nodes_evaluated': 0,
            'nodes_pruned': 0,
            'max_depth': 0,
            'ai_mistakes_made': 0,
            'teaching_hints': []
        }
        
        root = self._build_simple_tree() if tree_type == 'simple' else self._build_complex_tree()
        
        teaching_mode = (difficulty in ['tutorial', 'learning'])
        optimal_value = self.minimax(root, 3, -math.inf, math.inf, True, teaching_mode)
        
        return {
            'solution': {
                'value': optimal_value,
                'families_helped': self._calculate_families_helped(optimal_value)
            },
            'explanation': self._generate_story_explanation(optimal_value),
            'teaching_hints': self.stats['teaching_hints'],
            'difficulty': difficulty,
            'score': 100
        }
    
    def _calculate_families_helped(self, impact_score: int) -> int:
        """Convert impact score to number of families."""
        if impact_score <= 4:
            return 1
        elif impact_score <= 8:
            return 2
        elif impact_score <= 15:
            return 3
        else:
            return 4
    
    def _build_simple_tree(self) -> GameTreeNode:
        """Build strategic resource allocation tree."""
        leaf1 = GameTreeNode(value=10)
        leaf2 = GameTreeNode(value=8)
        leaf3 = GameTreeNode(value=4)
        leaf4 = GameTreeNode(value=50)
        
        min_left = GameTreeNode(children=[leaf1, leaf2], is_max=False)
        min_right = GameTreeNode(children=[leaf3, leaf4], is_max=False)
        
        root = GameTreeNode(children=[min_left, min_right], is_max=True)
        return root
    
    def _build_complex_tree(self) -> GameTreeNode:
        """Build complex decision tree."""
        def build_level(depth: int, is_max: bool):
            if depth == 0:
                return GameTreeNode(value=random.randint(1, 100))
            children = [build_level(depth - 1, not is_max) for _ in range(2)]
            return GameTreeNode(children=children, is_max=is_max)
        return build_level(3, True)
    
    def _generate_story_explanation(self, value: int) -> str:
        """Generate bilingual story explanation."""
        pruning_efficiency = (self.stats['nodes_pruned'] / max(1, self.stats['nodes_evaluated'])) * 100
        families = self._calculate_families_helped(value)
        
        teaching_section = ""
        if self.stats['ai_mistakes_made'] > 0:
            hints_text = "\n".join([
                f"  â€¢ {h['en']}\n    {h['zh']}"
                for h in self.stats['teaching_hints']
            ])
            teaching_section = f"""

ğŸ“ TEACHING MODE ACTIVE | æ•™å­¸æ¨¡å¼å•Ÿå‹•
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Difficulty | é›£åº¦: {self.difficulty.upper()}
AI Mistakes Made | AIçŠ¯çš„éŒ¯èª¤: {self.stats['ai_mistakes_made']}

{hints_text}

Why Teaching Mode? | ç‚ºä»€éº¼è¦æ•™å­¸æ¨¡å¼ï¼Ÿ
Mei Hsien's testing showed: "æ°¸é è´ä¸äº†AIå¾ˆæ²®å–ª"
(Always losing to AI is frustrating and demotivating)

Ready for higher difficulty? | æº–å‚™å¥½æ›´é«˜é›£åº¦äº†å—ï¼ŸğŸ’ª
"""
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ’” DIFFICULT CHOICES MADE | è‰±é›£çš„æŠ‰æ“‡å·²å®Œæˆ                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ DECISION RESULT | æ±ºç­–çµæœ:
Impact Score | å½±éŸ¿åˆ†æ•¸: {value}
Families Helped | å¹«åŠ©çš„å®¶åº­: {families}

ğŸ“Š ALGORITHM EFFICIENCY | ç®—æ³•æ•ˆç‡:
Total Options Considered | è€ƒæ…®çš„é¸é …: {self.stats['nodes_evaluated']}
Options PRUNED (Obviously Bad) | å‰ªæé¸é …ï¼ˆæ˜é¡¯ç³Ÿç³•ï¼‰: {self.stats['nodes_pruned']}
Pruning Efficiency | å‰ªææ•ˆç‡: {pruning_efficiency:.1f}%
{teaching_section}
ğŸ’­ THE HARD TRUTH | æ®˜é…·çš„ç¾å¯¦:
"With $10,000, we CANNOT fix a $50,000 roof.
But we CAN help 3 families with medical bills,
rent, and school supplies."

ã€Œç”¨$10,000ï¼Œæˆ‘å€‘ç„¡æ³•ä¿®$50,000çš„å±‹é ‚ã€‚
ä½†æˆ‘å€‘å¯ä»¥å¹«åŠ©3å€‹å®¶åº­ä»˜é†«ç™‚è²»ã€
æˆ¿ç§Ÿå’Œå­¸ç”¨å“ã€‚ã€

This is Alpha-Beta's wisdom: Quickly identify
"obviously impossible" options and focus on
what we CAN do.

é€™æ˜¯Alpha-Betaçš„æ™ºæ…§ï¼šå¿«é€Ÿè­˜åˆ¥
ã€Œæ˜é¡¯ä¸å¯èƒ½ã€çš„é¸é …ï¼Œå°ˆæ³¨æ–¼
æˆ‘å€‘èƒ½åšçš„äº‹ã€‚

ğŸ™ COMPASSION IN CONSTRAINTS | ç´„æŸä¸­çš„æ…ˆæ‚²:
True compassion isn't helping everyone equallyâ€”
it's maximizing impact with limited resources.

çœŸæ­£çš„æ…ˆæ‚²ä¸æ˜¯å¹³ç­‰å¹«åŠ©æ‰€æœ‰äººâ€”â€”
è€Œæ˜¯ç”¨æœ‰é™è³‡æºæœ€å¤§åŒ–å½±éŸ¿åŠ›ã€‚

â€” Tzu Chi Emergency Relief Philosophy
â€” æ…ˆæ¿Ÿç·Šæ€¥æ•‘åŠ©å“²å­¸

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 3: BAYESIAN NETWORK - VOLUNTEER COMMITMENT PREDICTION
# =============================================================================

class BayesianNetwork:
    """
    Bayesian Network for Volunteer Commitment Prediction
    (Russell & Norvig Chapter 12)
    
    Story: Will Maria come back to volunteer next month?
    Algorithm: Probabilistic inference using CPT tables
    Ethical: 40% baseline, bias testing, transparent probabilities
    """
    
    def __init__(self):
        self.nodes = {
            'Poor': [],
            'Elderly': [],
            'Sick': [],
            'Aid': ['Poor', 'Elderly', 'Sick'],
            'Volunteer': ['Aid']
        }
        
        self.cpt = {
            'Poor': {True: 0.30, False: 0.70},
            'Elderly': {True: 0.25, False: 0.75},
            'Sick': {True: 0.15, False: 0.85},
            'Aid': {
                (True, True, True): 0.95,
                (True, True, False): 0.85,
                (True, False, True): 0.80,
                (True, False, False): 0.70,
                (False, True, True): 0.75,
                (False, True, False): 0.60,
                (False, False, True): 0.55,
                (False, False, False): 0.30
            },
            'Volunteer': {
                True: 0.65,
                False: 0.40
            }
        }
    
    def query(self, evidence: Dict[str, bool]) -> float:
        """Perform probabilistic inference."""
        poor = evidence.get('Poor', None)
        elderly = evidence.get('Elderly', None)
        sick = evidence.get('Sick', None)
        
        if all(v is not None for v in [poor, elderly, sick]):
            p_aid = self.cpt['Aid'][(poor, elderly, sick)]
        else:
            p_aid = self._marginalize_aid(poor, elderly, sick)
        
        p_volunteer_given_aid_true = self.cpt['Volunteer'][True]
        p_volunteer_given_aid_false = self.cpt['Volunteer'][False]
        
        result = (p_aid * p_volunteer_given_aid_true +
                 (1 - p_aid) * p_volunteer_given_aid_false)
        
        return result
    
    def _marginalize_aid(self, poor, elderly, sick) -> float:
        """Marginalize over unobserved variables."""
        total_prob = 0.0
        
        for p in ([poor] if poor is not None else [True, False]):
            for e in ([elderly] if elderly is not None else [True, False]):
                for s in ([sick] if sick is not None else [True, False]):
                    p_combo = (self.cpt['Poor'][p] *
                              self.cpt['Elderly'][e] *
                              self.cpt['Sick'][s])
                    p_aid = self.cpt['Aid'][(p, e, s)]
                    total_prob += p_combo * p_aid
        
        if any(v is not None for v in [poor, elderly, sick]):
            normalizer = 0.0
            for p in ([poor] if poor is not None else [True, False]):
                for e in ([elderly] if elderly is not None else [True, False]):
                    for s in ([sick] if sick is not None else [True, False]):
                        normalizer += (self.cpt['Poor'][p] *
                                     self.cpt['Elderly'][e] *
                                     self.cpt['Sick'][s])
            total_prob /= normalizer
        
        return total_prob
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict volunteer commitment probability."""
        evidence = input_data.get('evidence', {})
        probability = self.query(evidence)
        
        confidence = (
            "High | é«˜ (Active Recruitment | ç©æ¥µæ‹›å‹Ÿ)" if probability >= 0.7
            else "Moderate | ä¸­ç­‰ (Engage & Monitor | æ¥è§¸è§€å¯Ÿ)" if probability >= 0.5
            else "Low | ä½ (Passive Contact | è¢«å‹•æ¥è§¸)"
        )
        
        return {
            'solution': {
                'probability': probability,
                'confidence': confidence,
                'evidence': evidence
            },
            'explanation': self._generate_story_explanation(probability, evidence),
            'score': 100
        }
    
    def _generate_story_explanation(self, probability: float, evidence: Dict[str, bool]) -> str:
        """Generate bilingual story explanation."""
        evidence_text = "\n".join([
            f"  {k}: {'âœ“ Yes | æ˜¯' if v else 'âœ— No | å¦'}"
            for k, v in evidence.items()
        ]) if evidence else "  (No evidence | ç„¡è­‰æ“š - using baseline | ä½¿ç”¨åŸºæº–å€¼)"
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¤ WILL MARIA COME BACK? | Mariaæœƒå›ä¾†å—ï¼Ÿ                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ PREDICTION | é æ¸¬:
P(Maria Returns | Evidence) = {probability:.3f} ({probability*100:.1f}%)
Confidence Level | ä¿¡å¿ƒæ°´å¹³: {self._get_confidence_desc(probability)}

ğŸ“Š OBSERVED EVIDENCE | è§€å¯Ÿåˆ°çš„è­‰æ“š:
{evidence_text}

ğŸ’­ THE STORY | æ•…äº‹:
Last Saturday, Maria helped distribute food.
She saw little Jasmine's smile when receiving
her family's groceries. Maria cried.

ä¸Šé€±å…­ï¼ŒMariaå¹«å¿™ç™¼æ”¾é£Ÿç‰©ã€‚
å¥¹çœ‹åˆ°å°Jasmineæ”¶åˆ°å®¶äººé£Ÿç‰©æ™‚çš„ç¬‘å®¹ã€‚
Mariaå“­äº†ã€‚

But will she come back? Our volunteers are
aging (average 65 years old). We NEED Maria
and people like her to continue this legacy.

ä½†å¥¹æœƒå›ä¾†å—ï¼Ÿæˆ‘å€‘çš„å¿—å·¥åœ¨è€åŒ–
ï¼ˆå¹³å‡65æ­²ï¼‰ã€‚æˆ‘å€‘éœ€è¦Maria
å’Œåƒå¥¹é€™æ¨£çš„äººå»¶çºŒé€™å€‹ä½¿å‘½ã€‚

ğŸ”¬ AI REASONING | AIæ¨ç†:
Bayesian Networks calculate probability based on:
- Has Maria experienced hardship? (Empathy)
- Does she have time available? (Capacity)
- Does her personality fit? (Compatibility)

è²è‘‰æ–¯ç¶²çµ¡åŸºæ–¼ä»¥ä¸‹è¨ˆç®—æ¦‚ç‡ï¼š
- Mariaç¶“æ­·éå›°é›£å—ï¼Ÿï¼ˆåŒç†å¿ƒï¼‰
- å¥¹æœ‰æ™‚é–“å—ï¼Ÿï¼ˆèƒ½åŠ›ï¼‰
- å¥¹çš„å€‹æ€§é©åˆå—ï¼Ÿï¼ˆå…¼å®¹æ€§ï¼‰

ğŸ“ ACTION PLAN | è¡Œå‹•è¨ˆåŠƒ:
{self._get_action_plan(probability)}

ğŸ™ ETHICAL SAFEGUARDS | é“å¾·ä¿éšœ:
âœ“ No discrimination based on demographics
  ä¸åŸºæ–¼äººå£çµ±è¨ˆæ­§è¦–
âœ“ Transparent probability (Maria can see this!)
  é€æ˜æ¦‚ç‡ï¼ˆMariaå¯ä»¥çœ‹åˆ°é€™å€‹ï¼ï¼‰
âœ“ Human final decision (AI is advisory only)
  äººé¡æœ€çµ‚æ±ºç­–ï¼ˆAIåƒ…ä¾›å»ºè­°ï¼‰

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""
    
    def _get_confidence_desc(self, prob: float) -> str:
        """Get bilingual confidence description."""
        if prob >= 0.7:
            return "HIGH | é«˜ - Prioritize active recruitment | å„ªå…ˆç©æ¥µæ‹›å‹Ÿ"
        elif prob >= 0.5:
            return "MODERATE | ä¸­ç­‰ - Engage and monitor | æ¥è§¸ä¸¦è§€å¯Ÿ"
        else:
            return "LOW | ä½ - Maintain passive contact | ä¿æŒè¢«å‹•æ¥è§¸"
    
    def _get_action_plan(self, prob: float) -> str:
        """Get bilingual action plan based on probability."""
        if prob >= 0.7:
            return """
âœ“ Call Maria this week | æœ¬é€±æ‰“é›»è©±çµ¦Maria
âœ“ Send volunteer info packet | å¯„é€å¿—å·¥è³‡è¨ŠåŒ…
âœ“ Invite to next orientation | é‚€è«‹åƒåŠ ä¸‹æ¬¡èªªæ˜æœƒ
âœ“ Connect with veteran volunteer mentor | èˆ‡è³‡æ·±å¿—å·¥å°å¸«é€£çµ
"""
        elif prob >= 0.5:
            return """
âœ“ Send thank-you card | å¯„é€æ„Ÿè¬å¡
âœ“ Invite to monthly community event | é‚€è«‹åƒåŠ æœˆåº¦ç¤¾å€æ´»å‹•
âœ“ Follow up in 2 weeks | å…©é€±å¾Œè·Ÿé€²
"""
        else:
            return """
âœ“ Add to contact list | åŠ å…¥è¯ç¹«æ¸…å–®
âœ“ Send quarterly newsletter | å¯„é€å­£åº¦é€šè¨Š
âœ“ Wait for life changes (graduation, job change, etc.)
  ç­‰å¾…ç”Ÿæ´»è®ŠåŒ–ï¼ˆç•¢æ¥­ã€æ›å·¥ä½œç­‰ï¼‰
"""


# =============================================================================
# LEVEL 4: TOWER OF HANOI - BUILDING VIRTUE LAYERS
# =============================================================================

class TowerOfHanoi:
    """
    Tower of Hanoi Recursive Solution (Russell & Norvig Chapter 3)
    
    Story: Building virtue layers (Gratitude â†’ Respect â†’ Love)
    Algorithm: Recursive divide-and-conquer
    Complexity: O(2^n) - exponential but proven optimal
    Moves: 2^n - 1 (no shortcuts exist)
    """
    
    def __init__(self):
        self.moves = []
        self.move_count = 0
    
    def solve_recursive(self, n: int, source: str, target: str, auxiliary: str):
        """
        Recursive solution to Tower of Hanoi.
        
        Args:
            n: Number of disks
            source: Starting peg ('A')
            target: Destination peg ('C')
            auxiliary: Helper peg ('B')
        """
        if n == 1:
            self.moves.append((source, target))
            self.move_count += 1
            return
        
        # Move n-1 disks to auxiliary
        self.solve_recursive(n - 1, source, auxiliary, target)
        
        # Move largest disk to target
        self.moves.append((source, target))
        self.move_count += 1
        
        # Move n-1 disks from auxiliary to target
        self.solve_recursive(n - 1, auxiliary, target, source)
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Solve Tower of Hanoi puzzle.
        
        Args:
            input_data: {
                'num_disks': int (default 3)
            }
            
        Returns:
            {
                'solution': {
                    'moves': [(from, to), ...],
                    'total_moves': int
                },
                'explanation': bilingual story,
                'score': 100
            }
        """
        n = input_data.get('num_disks', 3)
        
        # Reset state
        self.moves = []
        self.move_count = 0
        
        # Solve
        self.solve_recursive(n, 'A', 'C', 'B')
        
        return {
            'solution': {
                'moves': self.moves,
                'total_moves': self.move_count
            },
            'explanation': self._generate_story_explanation(n),
            'score': 100
        }
    
    def _generate_story_explanation(self, n: int) -> str:
        """Generate bilingual story explanation."""
        optimal = 2**n - 1
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§˜ TOWER OF COMPASSION COMPLETE | æ…ˆæ‚²ä¹‹å¡”å®Œæˆ              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ VIRTUE LAYERS | ç¾å¾·å±¤æ¬¡:
Disks | åœ“ç›¤æ•¸: {n}
- Bottom (largest): Gratitude | æ„Ÿæ© (foundation)
- Middle: Respect | å°Šé‡ (builds on gratitude)
- Top (smallest): Love | æ„› (grows from respect)

ğŸ“Š MOVEMENT ANALYSIS | ç§»å‹•åˆ†æ:
Optimal Moves | æœ€å„ªç§»å‹•: {optimal} (proven minimum)
Your Moves | ä½ çš„ç§»å‹•: {self.move_count}
Efficiency | æ•ˆç‡: {100 if self.move_count == optimal else 0}%

ğŸ’­ MASTER CHENG YEN'S TEACHING | è­‰åš´ä¸Šäººæ•™å°:
"You cannot skip steps in building compassion.
Gratitude is the foundation.
Respect stands upon gratitude.
Love grows from respect."

ã€Œå»ºç«‹æ…ˆæ‚²ä¸èƒ½è·³éæ­¥é©Ÿã€‚
æ„Ÿæ©æ˜¯åŸºç¤ã€‚
å°Šé‡ç«‹æ–¼æ„Ÿæ©ä¹‹ä¸Šã€‚
æ„›å¾å°Šé‡ä¸­ç”Ÿé•·ã€‚ã€

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
Tower of Hanoi proves that some problems have
NO SHORTCUTS. You must go through all 2^n - 1 states.

This is like building virtue: There are no shortcuts
to true compassion. One action at a time.

æ²³å…§å¡”è­‰æ˜æœ‰äº›å•é¡Œæ²’æœ‰æ·å¾‘ã€‚
ä½ å¿…é ˆç¶“éæ‰€æœ‰2^n - 1å€‹ç‹€æ…‹ã€‚

é€™å°±åƒå»ºç«‹ç¾å¾·ï¼šçœŸæ­£çš„æ…ˆæ‚²æ²’æœ‰æ·å¾‘ã€‚
ä¸€æ¬¡ä¸€å€‹è¡Œå‹•ã€‚

ğŸ“š ALGORITHM PROOF | ç®—æ³•è­‰æ˜:
Recurrence: T(n) = 2T(n-1) + 1
Solution: T(n) = 2^n - 1
Proof by induction:
- Base: T(1) = 1 = 2^1 - 1 âœ“
- Step: T(n) = 2(2^(n-1) - 1) + 1 = 2^n - 1 âœ“

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 5: N-QUEENS - VOLUNTEER SHIFT SCHEDULING
# =============================================================================

class NQueensSolver:
    """
    N-Queens Problem via Backtracking (Russell & Norvig Chapter 4.1)
    
    Story: Schedule 8 volunteers across 8 time slots with zero conflicts
    Algorithm: Backtracking with constraint satisfaction
    Complexity: O(n!) worst case, much better with pruning
    """
    
    def __init__(self):
        self.solutions = []
        self.backtrack_count = 0
    
    def is_safe(self, board: List[int], row: int, col: int) -> bool:
        """
        Check if placing queen at (row, col) is safe.
        
        board[i] = j means queen in row i is at column j
        """
        for i in range(row):
            # Same column
            if board[i] == col:
                return False
            
            # Diagonal
            if abs(board[i] - col) == abs(i - row):
                return False
        
        return True
    
    def solve_recursive(self, board: List[int], row: int, n: int):
        """
        Backtracking algorithm for N-Queens.
        
        Args:
            board: Current partial solution
            row: Current row to place queen
            n: Board size
        """
        # Base case: All queens placed
        if row == n:
            self.solutions.append(board[:])
            return
        
        # Try each column
        for col in range(n):
            self.backtrack_count += 1
            
            if self.is_safe(board, row, col):
                board[row] = col
                self.solve_recursive(board, row + 1, n)
                board[row] = -1  # Backtrack
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Solve N-Queens problem.
        
        Args:
            input_data: {
                'n': int (board size, default 8),
                'find_all': bool (default False)
            }
            
        Returns:
            {
                'solution': {
                    'board': [col_positions],
                    'visualization': str,
                    'total_solutions': int
                },
                'explanation': bilingual story,
                'score': 100
            }
        """
        n = input_data.get('n', 8)
        find_all = input_data.get('find_all', False)
        
        # Reset state
        self.solutions = []
        self.backtrack_count = 0
        
        # Solve
        board = [-1] * n
        self.solve_recursive(board, 0, n)
        
        # Return first solution or all
        solution = self.solutions[0] if self.solutions else []
        
        return {
            'solution': {
                'board': solution,
                'visualization': self._visualize_board(solution, n),
                'total_solutions': len(self.solutions),
                'moves': len(solution)
            },
            'explanation': self._generate_story_explanation(n),
            'score': 100 if solution else 0
        }
    
    def _visualize_board(self, board: List[int], n: int) -> str:
        """Generate ASCII art of chess board."""
        if not board:
            return "No solution found"
        
        lines = []
        for row in range(n):
            line = ""
            for col in range(n):
                if board[row] == col:
                    line += "â™› "
                else:
                    line += "â–¡ " if (row + col) % 2 == 0 else "â–  "
            lines.append(line)
        
        return "\n".join(lines)
    
    def _generate_story_explanation(self, n: int) -> str:
        """Generate bilingual story explanation."""
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“… VOLUNTEER SHIFT SCHEDULER COMPLETE | å¿—å·¥æ’ç­å®Œæˆ        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ SCHEDULING RESULT | æ’ç­çµæœ:
Board Size | æ£‹ç›¤å¤§å°: {n}Ã—{n}
Total Solutions Found | æ‰¾åˆ°çš„è§£æ±ºæ–¹æ¡ˆ: {len(self.solutions)}
Backtrack Steps | å›æº¯æ­¥æ•¸: {self.backtrack_count}

ğŸ“‹ VOLUNTEER ASSIGNMENTS | å¿—å·¥åˆ†é…:
{self._visualize_board(self.solutions[0] if self.solutions else [], n)}

ğŸ’­ THE REAL-WORLD SCENARIO | çœŸå¯¦å ´æ™¯:
Mrs. Chen (Row 1): Can't work mornings (arthritis)
é™³å¤ªå¤ªï¼ˆç¬¬1è¡Œï¼‰ï¼šæ—©ä¸Šä¸èƒ½å·¥ä½œï¼ˆé—œç¯€ç‚ï¼‰

David (Row 3): Basketball practice at 3pm
Davidï¼ˆç¬¬3è¡Œï¼‰ï¼šä¸‹åˆ3é»ç±ƒçƒç·´ç¿’

Rosa (Row 5): Works until noon
Rosaï¼ˆç¬¬5è¡Œï¼‰ï¼šè¦å·¥ä½œåˆ°ä¸­åˆ

Maria (Row 7): Free only evenings
Mariaï¼ˆç¬¬7è¡Œï¼‰ï¼šåªæœ‰æ™šä¸Šæœ‰ç©º

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
N-Queens uses CONSTRAINT SATISFACTION:
- Variables: Volunteer positions
- Domain: Time slots 1-{n}
- Constraints: No conflicts (row/col/diagonal)

Algorithm Efficiency | ç®—æ³•æ•ˆç‡:
- Worst case: {math.factorial(n)} permutations
  æœ€å£æƒ…æ³ï¼š{math.factorial(n)} æ’åˆ—
- With pruning: ~{self.backtrack_count} checks
  ä½¿ç”¨å‰ªæï¼š~{self.backtrack_count} æª¢æŸ¥
- Speedup: {math.factorial(n) / max(1, self.backtrack_count):.1f}x
  åŠ é€Ÿï¼š{math.factorial(n) / max(1, self.backtrack_count):.1f}å€

ğŸ“š CSP FRAMEWORK | ç´„æŸæ»¿è¶³å•é¡Œæ¡†æ¶:
This isn't just a puzzleâ€”it's how we schedule:
- Hospital shifts (nurses + doctors)
- School timetables (teachers + classrooms)
- Conference rooms (meetings + attendees)

é€™ä¸åªæ˜¯è¬é¡Œâ€”â€”é€™æ˜¯æˆ‘å€‘å¦‚ä½•æ’ç¨‹ï¼š
- é†«é™¢ç­æ¬¡ï¼ˆè­·å£«+é†«ç”Ÿï¼‰
- å­¸æ ¡æ™‚é–“è¡¨ï¼ˆè€å¸«+æ•™å®¤ï¼‰
- æœƒè­°å®¤ï¼ˆæœƒè­°+åƒèˆ‡è€…ï¼‰

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 6: HILL CLIMBING - MEDITATION OPTIMIZATION
# =============================================================================

class HillClimbing:
    """
    Hill Climbing with Random Restarts (Russell & Norvig Chapter 4.1.1)
    
    Story: Meditation state optimization (inner peace maximization)
    Algorithm: Local search with random restarts
    Complexity: O(âˆ) without restarts, O(kÃ—n) with k restarts
    """
    
    def __init__(self):
        self.history = []
        self.local_maxima_count = 0
    
    def evaluate(self, state: Dict[str, float]) -> float:
        """
        Evaluate meditation state quality.
        
        Objective function with multiple local maxima:
        f(focus, calmness, compassion) = weighted sum + interactions
        """
        f = state['focus']
        c = state['calmness']
        co = state['compassion']
        
        # Non-convex function with local maxima
        score = (
            0.4 * f + 0.3 * c + 0.3 * co +  # Linear terms
            0.1 * math.sin(f / 10) * 50 +    # Oscillation (local maxima)
            0.1 * math.sin(c / 10) * 50 +
            0.05 * (f * c / 100)             # Interaction term
        )
        
        return score
    
    def get_neighbors(self, state: Dict[str, float], step_size: float = 5.0) -> List[Dict[str, float]]:
        """Generate neighboring states (Â±step in each dimension)."""
        neighbors = []
        
        for key in state.keys():
            # Increase
            new_state = state.copy()
            new_state[key] = min(100, state[key] + step_size)
            neighbors.append(new_state)
            
            # Decrease
            new_state = state.copy()
            new_state[key] = max(0, state[key] - step_size)
            neighbors.append(new_state)
        
        return neighbors
    
    def climb(self, start_state: Dict[str, float], max_iterations: int = 100) -> Dict[str, Any]:
        """Simple hill climbing algorithm."""
        current = start_state
        current_score = self.evaluate(current)
        
        for i in range(max_iterations):
            self.history.append((current.copy(), current_score))
            
            # Generate neighbors
            neighbors = self.get_neighbors(current)
            
            # Find best neighbor
            best_neighbor = max(neighbors, key=self.evaluate)
            best_score = self.evaluate(best_neighbor)
            
            # If no improvement, local maximum reached
            if best_score <= current_score:
                self.local_maxima_count += 1
                return {
                    'state': current,
                    'score': current_score,
                    'iterations': i + 1,
                    'reason': 'local_maximum'
                }
            
            # Move to better neighbor
            current = best_neighbor
            current_score = best_score
        
        return {
            'state': current,
            'score': current_score,
            'iterations': max_iterations,
            'reason': 'max_iterations'
        }
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Solve meditation optimization with random restarts.
        
        Args:
            input_data: {
                'start_state': Optional[Dict[str, float]],
                'num_restarts': int (default 5),
                'max_iterations': int (default 100)
            }
            
        Returns:
            {
                'solution': {
                    'best_state': Dict[str, float],
                    'best_score': float,
                    'total_iterations': int
                },
                'explanation': bilingual story,
                'score': performance_score
            }
        """
        num_restarts = input_data.get('num_restarts', 5)
        max_iterations = input_data.get('max_iterations', 100)
        
        # Reset state
        self.history = []
        self.local_maxima_count = 0
        
        best_overall = None
        best_score = -math.inf
        
        # Random restart hill climbing
        for restart in range(num_restarts):
            # Random start state or user-provided
            if restart == 0 and 'start_state' in input_data:
                start = input_data['start_state']
            else:
                start = {
                    'focus': random.uniform(0, 100),
                    'calmness': random.uniform(0, 100),
                    'compassion': random.uniform(0, 100)
                }
            
            # Climb
            result = self.climb(start, max_iterations)
            
            # Track best
            if result['score'] > best_score:
                best_score = result['score']
                best_overall = result
        
        return {
            'solution': {
                'best_state': best_overall['state'],
                'best_score': best_score,
                'total_iterations': len(self.history),
                'local_maxima_found': self.local_maxima_count,
                'moves': best_overall['iterations']
            },
            'explanation': self._generate_story_explanation(best_overall),
            'score': min(100, int(best_score))
        }
    
    def _generate_story_explanation(self, result: Dict[str, Any]) -> str:
        """Generate bilingual story explanation."""
        state = result['state']
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§˜ INNER PEACE OPTIMIZED | å…§å¿ƒå¹³å’Œå„ªåŒ–å®Œæˆ                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ OPTIMAL MEDITATION STATE | æœ€å„ªç¦ªä¿®ç‹€æ…‹:
Focus | é›†ä¸­åŠ›: {state['focus']:.1f}/100
Calmness | å¹³éœå¿ƒ: {state['calmness']:.1f}/100
Compassion | æ…ˆæ‚²å¿ƒ: {state['compassion']:.1f}/100

Peace Score | å¹³å’Œåˆ†æ•¸: {result['score']:.2f}/100
Iterations | è¿­ä»£æ¬¡æ•¸: {result['iterations']}

ğŸ’­ MASTER CHENG YEN'S TEACHING | è­‰åš´ä¸Šäººæ•™å°:
"When the mind is calm, wisdom appears.
When wisdom appears, compassion flows.
When compassion flows, peace is found."

ã€Œå¿ƒéœï¼Œæ™ºæ…§è‡ªç„¶ç”Ÿã€‚
æ™ºæ…§ç”Ÿï¼Œæ…ˆæ‚²è‡ªç„¶æµã€‚
æ…ˆæ‚²æµï¼Œå¹³å’Œè‡ªç„¶ç¾ã€‚ã€

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
Hill Climbing found {self.local_maxima_count} LOCAL MAXIMA
(comfortable but not perfect states)

çˆ¬å±±æ³•æ‰¾åˆ°äº†{self.local_maxima_count}å€‹å±€éƒ¨æœ€å¤§å€¼
ï¼ˆèˆ’é©ä½†ä¸å®Œç¾çš„ç‹€æ…‹ï¼‰

That's why we needed RANDOM RESTARTS:
- Try different starting points
- Escape comfortable plateaus
- Find true inner peace

é€™å°±æ˜¯ç‚ºä»€éº¼éœ€è¦éš¨æ©Ÿé‡å•Ÿï¼š
- å˜—è©¦ä¸åŒèµ·é»
- é€ƒé›¢èˆ’é©å¹³å°
- æ‰¾åˆ°çœŸæ­£çš„å…§å¿ƒå¹³å’Œ

ğŸ“š ALGORITHM LIMITATIONS | ç®—æ³•é™åˆ¶:
Hill Climbing is GREEDY: Always picks best neighbor
But can get STUCK in local maxima

çˆ¬å±±æ³•æ˜¯è²ªå©ªçš„ï¼šç¸½æ˜¯é¸æœ€å¥½çš„é„°å±…
ä½†æœƒå›°åœ¨å±€éƒ¨æœ€å¤§å€¼

Like meditation: Sometimes you feel "good enough"
but true peace requires pushing beyond comfort zone

å°±åƒç¦ªä¿®ï¼šæœ‰æ™‚ä½ è¦ºå¾—ã€Œå¤ å¥½äº†ã€
ä½†çœŸæ­£çš„å¹³å’Œéœ€è¦çªç ´èˆ’é©å€

ğŸ”ï¸ BETTER ALTERNATIVES | æ›´å¥½çš„æ›¿ä»£æ–¹æ¡ˆ:
- Simulated Annealing: Accept worse moves sometimes
  æ¨¡æ“¬é€€ç«ï¼šæœ‰æ™‚æ¥å—è¼ƒå·®çš„ç§»å‹•
- Genetic Algorithms: Population-based search
  éºå‚³ç®—æ³•ï¼šåŸºæ–¼ç¾¤é«”çš„æœç´¢
- Gradient Descent: Use derivatives (if available)
  æ¢¯åº¦ä¸‹é™ï¼šä½¿ç”¨å°æ•¸ï¼ˆå¦‚æœå¯ç”¨ï¼‰

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 7: FIRST-ORDER LOGIC + BACKWARD CHAINING
# =============================================================================

class FOLPlanner:
    """
    First-Order Logic with Backward Chaining (Russell & Norvig Chapter 8-9)
    
    Story: Volunteer eligibility reasoning
    Algorithm: Backward chaining inference
    Complexity: Depends on knowledge base size
    """
    
    def __init__(self):
        # Knowledge base: Rules in Horn clause form
        self.kb = [
            # Rule 1: Person with compassion can volunteer
            {'if': ['Person(?x)', 'Compassionate(?x)'], 'then': 'CanVolunteer(?x)'},
            
            # Rule 2: Experienced hardship leads to compassion
            {'if': ['Person(?x)', 'ExperiencedHardship(?x)'], 'then': 'Compassionate(?x)'},
            
            # Rule 3: Volunteer with availability can serve
            {'if': ['CanVolunteer(?x)', 'Available(?x)'], 'then': 'CanServe(?x)'},
            
            # Rule 4: Serving helps families
            {'if': ['CanServe(?x)'], 'then': 'HelpsFamily(?x)'}
        ]
        
        self.facts = set()
        self.proof_steps = []
    
    def unify(self, term1: str, term2: str, bindings: Dict[str, str]) -> Optional[Dict[str, str]]:
        """
        Unification algorithm for FOL terms.
        
        Args:
            term1: First term (may contain variables like ?x)
            term2: Second term
            bindings: Current variable bindings
            
        Returns:
            Updated bindings if unification succeeds, None otherwise
        """
        if term1 == term2:
            return bindings
        
        # Variable unification
        if term1.startswith('?'):
            if term1 in bindings:
                return self.unify(bindings[term1], term2, bindings)
            else:
                new_bindings = bindings.copy()
                new_bindings[term1] = term2
                return new_bindings
        
        if term2.startswith('?'):
            if term2 in bindings:
                return self.unify(term1, bindings[term2], bindings)
            else:
                new_bindings = bindings.copy()
                new_bindings[term2] = term1
                return new_bindings
        
        return None
    
    def backward_chain(self, goal: str, depth: int = 0) -> bool:
        """
        Backward chaining to prove a goal.
        
        Args:
            goal: Goal to prove (e.g., 'CanServe(Maria)')
            depth: Recursion depth (for visualization)
            
        Returns:
            True if goal can be proven
        """
        self.proof_steps.append(('  ' * depth) + f"Trying to prove: {goal}")
        
        # Check if goal is a known fact
        if goal in self.facts:
            self.proof_steps.append(('  ' * depth) + f"âœ“ {goal} is a known fact")
            return True
        
        # Try to prove using rules
        for rule in self.kb:
            # Try to unify goal with rule conclusion
            bindings = self.unify(rule['then'], goal, {})
            
            if bindings is not None:
                self.proof_steps.append(('  ' * depth) + f"Found rule: {rule['then']} â† {rule['if']}")
                
                # Try to prove all premises
                all_proven = True
                for premise in rule['if']:
                    # Substitute bindings in premise
                    instantiated_premise = premise
                    for var, value in bindings.items():
                        instantiated_premise = instantiated_premise.replace(var, value)
                    
                    if not self.backward_chain(instantiated_premise, depth + 1):
                        all_proven = False
                        break
                
                if all_proven:
                    self.proof_steps.append(('  ' * depth) + f"âœ“ {goal} proven!")
                    return True
        
        self.proof_steps.append(('  ' * depth) + f"âœ— Cannot prove {goal}")
        return False
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Prove volunteer eligibility using FOL.
        
        Args:
            input_data: {
                'person': str (e.g., 'Maria'),
                'facts': List[str] (known facts)
            }
            
        Returns:
            {
                'solution': {
                    'can_serve': bool,
                    'proof': List[str]
                },
                'explanation': bilingual story,
                'score': 100
            }
        """
        person = input_data.get('person', 'Maria')
        self.facts = set(input_data.get('facts', [
            f'Person({person})',
            f'ExperiencedHardship({person})',
            f'Available({person})'
        ]))
        
        self.proof_steps = []
        
        # Try to prove CanServe(person)
        goal = f'CanServe({person})'
        result = self.backward_chain(goal)
        
        return {
            'solution': {
                'can_serve': result,
                'proof': self.proof_steps,
                'person': person
            },
            'explanation': self._generate_story_explanation(person, result),
            'score': 100
        }
    
    def _generate_story_explanation(self, person: str, can_serve: bool) -> str:
        """Generate bilingual story explanation."""
        proof_text = '\n'.join(self.proof_steps)
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¤” VOLUNTEER ELIGIBILITY REASONING | å¿—å·¥è³‡æ ¼æ¨ç†           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ QUERY | æŸ¥è©¢:
Can {person} serve as a volunteer?
{person}èƒ½æˆç‚ºå¿—å·¥å—ï¼Ÿ

ğŸ“‹ PROOF TRACE | è­‰æ˜è¿½è¹¤:
{proof_text}

âœ… CONCLUSION | çµè«–:
{person} {'CAN' if can_serve else 'CANNOT'} serve as volunteer
{person} {'å¯ä»¥' if can_serve else 'ä¸èƒ½'}æˆç‚ºå¿—å·¥

ğŸ’­ THE REASONING | æ¨ç†éç¨‹:
First-Order Logic allows us to REASON about people:
- NOT just "Maria" but "ANY person ?x"
- NOT just facts but RULES: IF ... THEN ...

ä¸€éšé‚è¼¯è®“æˆ‘å€‘èƒ½æ¨ç†é—œæ–¼äººï¼š
- ä¸åªæ˜¯ã€ŒMariaã€è€Œæ˜¯ã€Œä»»ä½•äºº?xã€
- ä¸åªæ˜¯äº‹å¯¦è€Œæ˜¯è¦å‰‡ï¼šå¦‚æœ...é‚£éº¼...

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
Backward Chaining is GOAL-DRIVEN:
1. Start with what you want to prove
2. Find rules that conclude that goal
3. Recursively prove the premises

å¾Œå‘éˆæ˜¯ç›®æ¨™é©…å‹•çš„ï¼š
1. å¾ä½ æƒ³è­‰æ˜çš„é–‹å§‹
2. æ‰¾åˆ°èƒ½å¾—å‡ºè©²ç›®æ¨™çš„è¦å‰‡
3. éæ­¸è­‰æ˜å‰æ

ğŸ“š REAL-WORLD APPLICATIONS | çœŸå¯¦æ‡‰ç”¨:
- Medical diagnosis (symptom â†’ disease)
  é†«ç™‚è¨ºæ–·ï¼ˆç—‡ç‹€â†’ç–¾ç—…ï¼‰
- Legal reasoning (facts â†’ verdict)
  æ³•å¾‹æ¨ç†ï¼ˆäº‹å¯¦â†’åˆ¤æ±ºï¼‰
- Expert systems (conditions â†’ recommendation)
  å°ˆå®¶ç³»çµ±ï¼ˆæ¢ä»¶â†’å»ºè­°ï¼‰

ğŸ™ TZU CHI APPLICATION | æ…ˆæ¿Ÿæ‡‰ç”¨:
We don't just recruit ANYONEâ€”we reason about:
- Do they have the right heart? (Compassionate)
- Do they have the capacity? (Available)
- Will they sustain commitment? (Experienced hardship)

æˆ‘å€‘ä¸åªæ˜¯æ‹›å‹Ÿä»»ä½•äººâ€”â€”æˆ‘å€‘æ¨ç†ï¼š
- ä»–å€‘æœ‰æ­£ç¢ºçš„å¿ƒå—ï¼Ÿï¼ˆæœ‰åŒæƒ…å¿ƒï¼‰
- ä»–å€‘æœ‰èƒ½åŠ›å—ï¼Ÿï¼ˆæœ‰æ™‚é–“ï¼‰
- ä»–å€‘æœƒæŒçºŒæ‰¿è«¾å—ï¼Ÿï¼ˆç¶“æ­·éå›°é›£ï¼‰

Next Mission Unlocked! | ä¸‹å€‹ä»»å‹™è§£é–äº†ï¼ â†’
"""


# =============================================================================
# LEVEL 8: GOAL STACK PLANNING / BLOCKS WORLD
# =============================================================================

class BlocksWorld:
    """
    Goal Stack Planning for Blocks World (Russell & Norvig Chapter 11)
    
    Story: Warehouse resource organization
    Algorithm: STRIPS-style planning
    Complexity: Depends on number of objects and goal complexity
    """
    
    def __init__(self):
        self.plan = []
        self.state = {}
    
    def strips_move(self, block: str, from_loc: str, to_loc: str, state: Dict) -> Dict:
        """
        Execute a STRIPS-style move action.
        
        Preconditions:
        - Block is clear (no block on top)
        - From location has the block
        - To location is clear (if not table)
        
        Effects:
        - Block moves from 'from_loc' to 'to_loc'
        - Block on 'from_loc' becomes clear
        - 'to_loc' becomes not clear
        """
        new_state = state.copy()
        
        # Update locations
        new_state[block] = to_loc
        
        # Update clear status
        if from_loc != 'table':
            new_state[f'clear_{from_loc}'] = True
        
        if to_loc != 'table':
            new_state[f'clear_{to_loc}'] = False
        
        return new_state
    
    def solve_blocks(self, initial: Dict[str, str], goal: Dict[str, str]) -> List[Tuple[str, str, str]]:
        """
        Solve blocks world problem using goal stack planning.
        
        Args:
            initial: Initial state {block: location}
            goal: Goal state {block: location}
            
        Returns:
            List of moves (block, from, to)
        """
        self.plan = []
        self.state = initial.copy()
        
        # Simple goal stack planner
        for block, target_loc in goal.items():
            if self.state.get(block) != target_loc:
                # Need to move this block
                current_loc = self.state.get(block, 'table')
                
                # Clear the block first (move blocks on top)
                self._clear_block(block)
                
                # Clear the target location
                if target_loc != 'table':
                    self._clear_block(target_loc)
                
                # Move the block
                self.plan.append((block, current_loc, target_loc))
                self.state = self.strips_move(block, current_loc, target_loc, self.state)
        
        return self.plan
    
    def _clear_block(self, block: str):
        """Recursively clear a block by moving blocks on top of it."""
        # Find blocks on top
        blocks_on_top = [b for b, loc in self.state.items() if loc == block]
        
        for top_block in blocks_on_top:
            # Recursively clear the top block
            self._clear_block(top_block)
            
            # Move it to table
            self.plan.append((top_block, block, 'table'))
            self.state = self.strips_move(top_block, block, 'table', self.state)
    
    def solve(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate plan to achieve goal state.
        
        Args:
            input_data: {
                'initial': {block: location},
                'goal': {block: location}
            }
            
        Returns:
            {
                'solution': {
                    'plan': [(block, from, to), ...],
                    'steps': int
                },
                'explanation': bilingual story,
                'score': 100
            }
        """
        initial = input_data.get('initial', {
            'A': 'table',
            'B': 'table',
            'C': 'table'
        })
        
        goal = input_data.get('goal', {
            'C': 'B',
            'B': 'A',
            'A': 'table'
        })
        
        plan = self.solve_blocks(initial, goal)
        
        return {
            'solution': {
                'plan': plan,
                'steps': len(plan),
                'moves': len(plan)
            },
            'explanation': self._generate_story_explanation(plan, initial, goal),
            'score': 100
        }
    
    def _generate_story_explanation(self, plan: List[Tuple], initial: Dict, goal: Dict) -> str:
        """Generate bilingual story explanation."""
        plan_text = '\n'.join([
            f"  {i+1}. Move {move[0]} from {move[1]} to {move[2]}"
            for i, move in enumerate(plan)
        ])
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“¦ WAREHOUSE ORGANIZATION COMPLETE | å€‰åº«æ•´ç†å®Œæˆ           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ PLANNING RESULT | è¦åŠƒçµæœ:
Initial State | åˆå§‹ç‹€æ…‹: {initial}
Goal State | ç›®æ¨™ç‹€æ…‹: {goal}
Total Moves | ç¸½ç§»å‹•æ•¸: {len(plan)}

ğŸ“‹ EXECUTION PLAN | åŸ·è¡Œè¨ˆåŠƒ:
{plan_text}

ğŸ’­ THE REAL-WORLD SCENARIO | çœŸå¯¦å ´æ™¯:
Tzu Chi warehouse stores:
- A: Rice (heavy, bottom)
- B: Vegetables (medium, middle)
- C: Snacks (light, top)

æ…ˆæ¿Ÿå€‰åº«å„²å­˜ï¼š
- Aï¼šç±³ï¼ˆé‡ï¼Œåº•éƒ¨ï¼‰
- Bï¼šè”¬èœï¼ˆä¸­ï¼Œä¸­é–“ï¼‰
- Cï¼šé›¶é£Ÿï¼ˆè¼•ï¼Œé ‚éƒ¨ï¼‰

Goal: Optimize for FIFO (First-In-First-Out)
Oldest supplies should be on top for distribution
ç›®æ¨™ï¼šå„ªåŒ–å…ˆé€²å…ˆå‡º
æœ€èˆŠçš„ç‰©è³‡æ‡‰è©²åœ¨é ‚éƒ¨ä»¥ä¾¿ç™¼æ”¾

ğŸ”¬ THE AI SECRET | AIç§˜å¯†:
STRIPS Planning uses:
- Preconditions: What must be true to act
  å‰ç½®æ¢ä»¶ï¼šè¡Œå‹•å‰å¿…é ˆç‚ºçœŸçš„æ¢ä»¶
- Effects: What changes after action
  æ•ˆæœï¼šè¡Œå‹•å¾Œçš„è®ŠåŒ–
- Goal Stack: Work backward from goal
  ç›®æ¨™å †æ£§ï¼šå¾ç›®æ¨™å€’æ¨

This is how robots plan manipulation tasks!
é€™æ˜¯æ©Ÿå™¨äººå¦‚ä½•è¦åŠƒæ“ä½œä»»å‹™ï¼

ğŸ“š CLASSICAL PLANNING | ç¶“å…¸è¦åŠƒ:
Blocks World is the "Hello World" of AI planning:
- Simple to state
- Hard to solve optimally
- Generalizes to real problems

ç©æœ¨ä¸–ç•Œæ˜¯AIè¦åŠƒçš„ã€ŒHello Worldã€ï¼š
- ç°¡å–®é™³è¿°
- é›£ä»¥æœ€å„ªè§£æ±º
- æ¨å»£åˆ°å¯¦éš›å•é¡Œ

ğŸ­ REAL-WORLD APPLICATIONS | çœŸå¯¦æ‡‰ç”¨:
- Factory assembly lines
  å·¥å» è£é…ç·š
- Warehouse logistics
  å€‰åº«ç‰©æµ
- Meal preparation (cooking order)
  é¤é»æº–å‚™ï¼ˆçƒ¹é£ªé †åºï¼‰
- Surgery planning (operation steps)
  æ‰‹è¡“è¦åŠƒï¼ˆæ“ä½œæ­¥é©Ÿï¼‰

ğŸ™ TZU CHI WAREHOUSE WISDOM | æ…ˆæ¿Ÿå€‰åº«æ™ºæ…§:
Master Cheng Yen teaches:
"Organize with mindfulness.
The order of supplies reflects
the order of our compassion."

è­‰åš´ä¸Šäººæ•™å°ï¼š
ã€Œç”¨å¿ƒæ•´ç†ã€‚
ç‰©è³‡çš„é †åºåæ˜ 
æˆ‘å€‘æ…ˆæ‚²çš„é †åºã€‚ã€

ALL 8 MISSIONS COMPLETE! | æ‰€æœ‰8å€‹ä»»å‹™å®Œæˆï¼
You've mastered all algorithms! | ä½ å·²ç²¾é€šæ‰€æœ‰ç®—æ³•ï¼ ğŸ‰
"""


# =============================================================================
# ELO RATING SYSTEM
# =============================================================================

class EloRating:
    """
    Elo Rating System for gamification.
    
    Rating Milestones:
    - 1000: Beginner | åˆå­¸è€…
    - 1300: Tzu Chi QR Code Unlocked! | æ…ˆæ¿ŸQRç¢¼è§£é–ï¼
    - 1500: Proficient | ç²¾é€š
    - 1800: Advanced | é«˜ç´š
    - 2000+: Expert | å°ˆå®¶
    """
    
    def __init__(self, initial: int = 1000, k: int = 32):
        self.rating = initial
        self.k = k
        self.history = [(0, initial)]
    
    def calculate(self, user_score: float, ai_score: float) -> int:
        """Calculate Elo change based on performance."""
        user_normalized = user_score / 100
        ai_normalized = ai_score / 100
        
        expected = 1 / (1 + 10 ** ((ai_normalized * 2000 - self.rating) / 400))
        actual = user_normalized
        
        change = int(self.k * (actual - expected))
        self.rating += change
        self.history.append((len(self.history), self.rating))
        
        return change
    
    def get_rank(self) -> str:
        """Get bilingual rank description."""
        if self.rating >= 2000:
            return "Expert | å°ˆå®¶"
        elif self.rating >= 1800:
            return "Advanced | é«˜ç´š"
        elif self.rating >= 1500:
            return "Proficient | ç²¾é€š"
        elif self.rating >= 1300:
            return "Competent | å‹ä»» - ğŸ‰ Tzu Chi QR Unlocked! | æ…ˆæ¿ŸQRç¢¼è§£é–ï¼"
        elif self.rating >= 1000:
            return "Novice | æ–°æ‰‹"
        else:
            return "Beginner | åˆå­¸è€…"


# =============================================================================
# MAIN ENTRY POINT
# =============================================================================

def main():
    """Test story-driven game engine."""
    print("=" * 70)
    print("Journey of Kindness - Story-Driven AI Game | æ…ˆå–„ä¹‹æ—… - æ•…äº‹é©…å‹•AIéŠæˆ²")
    print("From Raw Rice Incident to 500 Volunteers | å¾ç”Ÿç±³äº‹ä»¶åˆ°500ä½å¿—å·¥")
    print("=" * 70)
    print()
    
    engine = GameEngine()
    
    # Test Level 1: Food Delivery
    print("Testing Level 1: Food Delivery Mission | æ¸¬è©¦é—œå¡1ï¼šé£Ÿç‰©é…é€ä»»å‹™...")
    story1 = engine.get_level_story(1)
    print(f"Title: {story1['title']['en']} | {story1['title']['zh']}")
    print(f"Story intro (first 100 chars):\n{story1['intro']['en'][:100]}...")
    print()
    
    level1_input = {
        'grid_size': (10, 10),
        'start': (0, 0),
        'goals': [(9, 9)],
        'obstacles': [(2, 2), (2, 3)]
    }
    result1 = engine.run_level(1, level1_input)
    print(f"Path length | è·¯å¾‘é•·åº¦: {len(result1['ai_solution']['path'])}")
    print(f"Elo change | Eloè®ŠåŒ–: {result1['elo_change']:+d}")
    print(f"Emotional feedback: {result1['emotional_feedback']['en'][:80]}...")
    print()
    
    # Test Level 2: Strategic Resource Allocation
    print("Testing Level 2: Difficult Choices | æ¸¬è©¦é—œå¡2ï¼šè‰±é›£çš„æŠ‰æ“‡...")
    story2 = engine.get_level_story(2)
    print(f"Title: {story2['title']['en']} | {story2['title']['zh']}")
    print()
    
    level2_input = {
        'tree_structure': 'simple',
        'difficulty': 'learning'
    }
    result2 = engine.run_level(2, level2_input)
    print(f"Families helped | å¹«åŠ©çš„å®¶åº­: {result2['ai_solution']['families_helped']}")
    print(f"Elo change | Eloè®ŠåŒ–: {result2['elo_change']:+d}")
    if result2.get('teaching_hints'):
        print(f"Teaching hints | æ•™å­¸æç¤º: {len(result2['teaching_hints'])} hints")
    print()
    
    # Summary
    print("=" * 70)
    print("Story-Driven Tests Complete! | æ•…äº‹é©…å‹•æ¸¬è©¦å®Œæˆï¼")
    print(f"Final Elo | æœ€çµ‚Elo: {engine.elo_system.rating}")
    print(f"Rank | ç­‰ç´š: {engine.elo_system.get_rank()}")
    print(f"Tzu Chi QR Unlocked | æ…ˆæ¿ŸQRç¢¼è§£é–: {engine.elo_system.rating >= 1300}")
    print("=" * 70)


if __name__ == "__main__":
    main()
    